---
layout: base
title: AI Pedagogy
author: Fred Gibbs
date: 2025-02-14
description: "Amaranth investigates AI pedagogy from a humanistic perspective: how undergraduate students develop critical AI fluency through open workflows, public scholarship, and interpretive practice at UNM."
header-image: /assets/images/headers/mechanical-turk.webp
header-title: AI Pedagogy
header-tier: section
header-filter: photo
header-zoom: 110%
header-position: center 20%
---

## Why this matters now

Artificial intelligence is reshaping how knowledge is made, organized, and interpreted. The debates it's generating—about authorship, bias, authority, and trust—are debates humanists have been having for decades. What makes a source reliable? Who decides what counts as knowledge? How do systems of power shape what gets preserved and what gets discarded?

Humanists shouldn't be on the outside looking in. The question isn't whether to engage with AI, but how—and on what terms. We help faculty and students explore boundaries of AI through targeted technical interventions. 


## AI as a bridge to digital work

For years, technical barriers have kept humanists from building the kinds of digital projects their scholarship deserved. Anything more than a Wordpress site full of ads was basically out of bounds, much less a design-forward digital exhibit, or a collaborative oral history project. Most scholars never cleared that threshold.

AI changes what's possible. When working with clearly structured, well-documented systems—like Amaranth's [Xanthan](https://xanthan-web.github.io) framework—AI assistants can handle the technical details while you focus on intellectual decisions. You don't need to master technical details to adjust a site's typography. You don't need to understand databases to organize your images. The technical code is still there (and adjustable once you learn more), but it's no longer a prerequisite for getting started.

This isn't about replacing or outsourcing expertise. It's about letting people with humanistic vision shape their own work and expand their technical skills without spending months learning infrastructure first. And in the process of building something real---a website, a digital project, a public-facing piece of scholarship---you start to understand how to push boundaries deliberately.


## Teaching an AI workflow, not doing it for you

We don't tell people to "just use AI" and send them off. We don't do the work for them, either. We guide collaborators through an **iterative AI workflow**: prompting, evaluating output, refining requests, asking for explanations to recognize when AI is helping and when it's heading down the wrong path. 

That iterative process is the pedagogy---and it can be used for humanist conversations as much as technical ones. Once you've learned to work with AI on technical problems—where the boundaries are clearer and the feedback is immediate—you've developed fluency that carries over into other contexts: research, teaching, writing, analysis.


## A gateway to broader AI engagement

We've found that working with AI on **technical tasks**—building a website, formatting a document, troubleshooting code—offers a lower-stakes entry point than asking AI to analyze a historical text or draft an argument. Technical work has clearer success criteria. You can see whether the CSS worked, whether the layout is right, whether the site builds correctly. There's less at stake intellectually, which makes it easier to experiment, fail, and learn.

This matters because many faculty and students approach AI with justified caution—concerns about plagiarism, intellectual shortcuts, or undermining the learning process. By starting with technical support for digital humanities work, we sidestep some of that defensiveness. Once people get comfortable using AI as a technical collaborator, they're better positioned to think critically about where else it might (or might not) belong in their scholarship and teaching.

Digital humanities projects become a training ground for AI fluency more broadly.


## The studio learns alongside you

We don't position ourselves as AI experts who have it figured out. We're practitioners—constantly using AI for technical work, design decisions, troubleshooting, documentation—and constantly learning where it helps and where it misleads, both in technical and humanistic contexts.

When we work with collaborators, we share what we're learning: This prompt structure worked. That output was overconfident. Here's where AI saved us hours, and here's where it sent us down a wrong path. This transparency isn't just pedagogical. It's honest. None of us have mastered this yet.


## Humanities skills are AI skills

The ability to evaluate a source isn't just a humanities habit. It's exactly what you need when an AI system gives you a confident-sounding answer that may or may not be grounded in anything real. The ability to recognize whose interests a particular framing serves isn't just a critical theory exercise. It's how you notice when an AI system reflects the assumptions of whoever built it. The ability to sit with ambiguity—to hold an interpretation rather than forcing a conclusion—is precisely the skill that makes someone a thoughtful rather than a reckless AI collaborator.

These interpretive habits—developed through close reading, archival research, historiographical training—translate directly into critical AI use. We think that connection deserves more attention than it's getting.


## Part of a new digital humanities moment

This approach to AI isn't separate from Amaranth's broader digital humanities work—it's central to it. As we discuss on the [Digital Humanities](/studio/digital-humanities) page, AI has dramatically lowered the barrier to entry for digital scholarship. You no longer need to learn a programming language to build something compelling or do sophisticated text analysis. You need good questions, editorial judgment, and the willingness to learn through making.

That shift opens up digital humanities to a much wider community of practitioners. It also demands a different kind of pedagogy—one that teaches critical collaboration with AI systems rather than technical mastery as a prerequisite.


## An evolving practice

Our work with AI isn't settled. We're learning semester by semester, project by project, constantly adjusting what we teach and how we guide people through these workflows. We document what we're discovering—what works, what doesn't, where the boundaries are—and share it as we go.

If you're working with AI in your teaching, your research, or your digital projects and want to compare notes, [reach out](/collaborate). This is the right moment to be figuring it out together.
