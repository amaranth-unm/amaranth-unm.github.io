---
layout: base
title: AI Pedagogy
author: Fred Gibbs
date: 2025-02-14
description: "Amaranth investigates AI pedagogy from a humanistic perspective: how undergraduate students develop critical AI fluency through open workflows, public scholarship, and interpretive practice at UNM."
header-image: /assets/images/headers/mechanical-turk.jpg
header-title: AI Pedagogy
header-tier: section
header-filter: photo
header-position: center center
---

## We're already in the middle of it

Artificial intelligence is reshaping how knowledge is made, organized, and interpreted. The debates it's generating—about authorship, bias, authority, and trust—are debates humanists have been having for decades. What makes a source reliable? Who decides what counts as knowledge? How do systems of power shape what gets preserved and what gets discarded? These aren't new questions. They're core questions for anyone trained in history, literature, philosophy, or the interpretive social sciences.

Which means humanists aren't on the outside of this moment looking in. They're in the middle of it, with tools that matter.


## AI changes what's possible 
Amaranth's approach to web development through [Xanthan](https://xanthan-web.github.io), its open-source website framework, is built around a specific insight: AI assistants work best when they have clearly structured, well-documented materials to work with. Xanthan uses named variables, modular components, and plain-language configuration so that users can direct AI to make sophisticated changes to their sites without writing code themselves. This isn't about replacing expertise---it's about redistributing creative control. The person with the intellectual vision should be able to shape the final product, even if they've never written a line of CSS.



## Humanities skills are AI skills

The ability to evaluate a source isn't just a humanities habit. It's exactly what you need when an AI system gives you a confident-sounding answer that may or may not be grounded in anything real. The ability to recognize whose interests a particular framing serves isn't just a critical theory exercise. It's how you notice when an AI system reflects the assumptions of whoever built and trained it. The ability to sit with ambiguity—to hold an interpretation rather than forcing a conclusion—is precisely the skill that makes someone a thoughtful rather than a reckless AI collaborator.

Humanistic AI fluency isn't a supplement to technical AI literacy. It's a different kind of capability entirely—and one that most STEM-centered AI education doesn't address. We think undergraduates deserve both.


## How we work with AI

Amaranth approaches AI in the studio and classrooms through open, transparent engagement. Rather than hiding AI use, we model responsible engagement in public:

- Students document their workflows—prompts, revisions, interpretive decisions—not as a compliance exercise, but as a reflective one. Documenting your process forces you to understand it.
- We build with open-source tools and public platforms, so the work is visible and the decisions are legible.
- We ask students to push back: to probe AI outputs, compare machine and human interpretations, and articulate where and why they diverge.
- We treat failure as data. An AI that gets something wrong—or produces something shallow—is a pedagogical opportunity, not a crisis.

One of the most productive questions we ask is: *what did sharing this work force you to think more carefully about?* Public scholarship is a forcing function for precision in a way that a private paper never is. AI accelerates that dynamic—it can produce a draft fast, but it can't decide what's worth saying.


## Humanities for AI

Amaranth also contributes to broader campus conversations about artificial intelligence—not as advocates for any particular technology, but as people with expertise in how knowledge gets made, interpreted, and contested. The humanities have something specific to say about data, representation, and the cultural assumptions embedded in AI systems. We're interested in saying it—in faculty governance, curriculum design, and community engagement.


## An ongoing investigation

Our work in AI pedagogy isn't settled. The landscape shifts semester by semester, and what works in one course may not translate to another. We're documenting what we're learning—through course designs, student projects, and collaborative reflection—and sharing it as we go. If you're thinking about AI in the classroom and want to compare notes, [reach out](/collaborate).
