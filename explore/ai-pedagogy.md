---
layout: base
title: AI Pedagogy
author: Fred Gibbs
date: 2025-02-14
description: "Amaranth investigates AI pedagogy from a humanistic perspective: how undergraduate students develop critical AI fluency through open workflows, public scholarship, and interpretive practice at UNM."
header-image: /assets/images/headers/mechanical-turk.jpg
header-title: AI Pedagogy
header-tier: section
header-filter: photo
header-position: center center
---

## We're already in the middle of it

Artificial intelligence is reshaping how knowledge is made, organized, and interpreted. The debates it's generating—about authorship, bias, authority, and trust—are debates humanists have been having for decades. What makes a source reliable? Who decides what counts as knowledge? How do systems of power shape what gets preserved and what gets discarded? These aren't new questions. They're core questions for anyone trained in history, literature, philosophy, or the interpretive social sciences.

Which means humanists aren't on the outside of this moment looking in. They're in the middle of it, with tools that matter.


## Why undergraduates

Most conversations about AI in higher education focus on faculty research—how scholars can use AI to analyze large text corpora, generate hypotheses, or accelerate workflows. Or they focus on a defensive question: how do we detect whether students used AI to cheat?

Both framings miss something important. Undergraduate students are already using AI in everything they do. The question isn't whether to engage with that reality—it's whether to engage thoughtfully. Students who move through four years of college using AI as a shortcut, without frameworks for evaluating what it tells them or understanding how it constructs knowledge, leave less equipped for intellectual and democratic life than they should be.

Amaranth focuses on undergraduates precisely because they're where the intervention matters most—not to police AI use, but to make it more conscious, more critical, and more powerful.


## Humanities skills are AI skills

The ability to evaluate a source isn't just a humanities habit. It's exactly what you need when an AI system gives you a confident-sounding answer that may or may not be grounded in anything real. The ability to recognize whose interests a particular framing serves isn't just a critical theory exercise. It's how you notice when an AI system reflects the assumptions of whoever built and trained it. The ability to sit with ambiguity—to hold an interpretation rather than forcing a conclusion—is precisely the skill that makes someone a thoughtful rather than a reckless AI collaborator.

Humanistic AI fluency isn't a supplement to technical AI literacy. It's a different kind of capability entirely—and one that most STEM-centered AI education doesn't address. We think undergraduates deserve both.


## How we work

Amaranth approaches AI in the classroom through open, transparent engagement. Rather than hiding AI use, we model responsible engagement in public:

- Students document their workflows—prompts, revisions, interpretive decisions—not as a compliance exercise, but as a reflective one. Documenting your process forces you to understand it.
- We build with open-source tools and public platforms, so the work is visible and the decisions are legible.
- We ask students to push back: to probe AI outputs, compare machine and human interpretations, and articulate where and why they diverge.
- We treat failure as data. An AI that gets something wrong—or produces something shallow—is a pedagogical opportunity, not a crisis.

One of the most productive questions we ask is: *what did sharing this work force you to think more carefully about?* Public scholarship is a forcing function for precision in a way that a private paper never is. AI accelerates that dynamic—it can produce a draft fast, but it can't decide what's worth saying.


## Humanities for AI

Amaranth also contributes to broader campus conversations about artificial intelligence—not as advocates for any particular technology, but as people with expertise in how knowledge gets made, interpreted, and contested. The humanities have something specific to say about data, representation, and the cultural assumptions embedded in AI systems. We're interested in saying it—in faculty governance, curriculum design, and community engagement.

We're not trying to slow AI down. We're trying to ensure that humanistic thinking has a seat at the table while the decisions are still being made.


## An ongoing investigation

Our work in AI pedagogy isn't settled. The landscape shifts semester by semester, and what works in one course may not translate to another. We're documenting what we're learning—through course designs, student projects, and collaborative reflection—and sharing it as we go. If you're thinking about AI in the classroom and want to compare notes, [reach out](/collaborate).
